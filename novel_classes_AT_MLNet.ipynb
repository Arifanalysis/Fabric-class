{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyOwnfyz5ETlzKznh7mfF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arifanalysis/Fabric-class/blob/main/novel_classes_AT_MLNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYITgIX9wkZN"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d sobouhiarif/fabric-classifications\n",
        "#kaggle datasets download -d sobouhiarif/fabric-defect-test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3-vdGyI0zxuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = '/content/fabric-classifications.zip'\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extract_path = '/content/Fabric FDD/Fabric_classification'\n",
        "\n",
        "# Unzip the folder\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "pv2oitlFz3MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "folder_path = \"/content/Fabric FDD/Fabric_classification\"\n",
        "zip_file_path = \"/content/fabric-classifications.zip\"\n",
        "shutil.make_archive(zip_file_path[:-4], 'zip', folder_path)"
      ],
      "metadata": {
        "id": "a4POwXoHz7lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.applications import MobileNet\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Attention layer class\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "# Function to load the dataset with hierarchical structure\n",
        "def load_dataset():\n",
        "    base_dir = '/content/Fabric FDD/Fabric_classification/Fabric classification'\n",
        "    # Define hierarchical categories for Weaving and Knitting\n",
        "    subcategories = {\n",
        "        'Weaving_gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Weaving_dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Weaving_printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']\n",
        "    }\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    categories = list(subcategories.keys())\n",
        "    category_counts = {category: 0 for category in categories}\n",
        "\n",
        "    for label, category in enumerate(categories):\n",
        "        for defect in subcategories[category]:\n",
        "            category_dir = os.path.join(base_dir, category, defect)\n",
        "            if not os.path.exists(category_dir):\n",
        "                print(f\"Directory {category_dir} does not exist. Skipping this category.\")\n",
        "                continue\n",
        "            for filename in os.listdir(category_dir):\n",
        "                if filename.endswith('.jpg'):\n",
        "                    img = cv2.imread(os.path.join(category_dir, filename))\n",
        "                    img = cv2.resize(img, (128, 128))  # Resize image to 128x128\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                    category_counts[category] += 1  # Count the images for each category\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    print(\"Image counts per category:\", category_counts)  # Print the counts for debugging\n",
        "\n",
        "    return images, labels, categories\n",
        "\n",
        "# Load the dataset\n",
        "images, labels, categories = load_dataset()\n",
        "\n",
        "# Ensure there are images loaded\n",
        "if len(images) == 0:\n",
        "    raise ValueError(\"No images found. Please check the dataset path and ensure images are available.\")\n",
        "\n",
        "# Preprocess the images (normalize pixel values)\n",
        "images = images.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "labels = to_categorical(labels, num_classes=len(categories))\n",
        "\n",
        "# Reshape images for LSTM input\n",
        "images = images.reshape(images.shape[0], 1, 128, 128, 3)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "trainX, testX, trainY, testY = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Load pre-trained MobileNet without the top layers\n",
        "feature_extractor = MobileNet(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Freeze the weights of the pre-trained model\n",
        "for layer in feature_extractor.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Use TimeDistributed to apply the MobileNet to each image in the sequence\n",
        "model.add(TimeDistributed(feature_extractor, input_shape=(1, 128, 128, 3)))\n",
        "model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "\n",
        "# Add LSTM layer\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add Attention layer\n",
        "model.add(AttentionLayer())\n",
        "\n",
        "# Add Dense layers for classification\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer for final classification\n",
        "model.add(Dense(len(categories), activation='softmax', kernel_regularizer='l2'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())\n",
        "\n",
        "# Callbacks\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(trainX, trainY, epochs=90, batch_size=32, validation_data=(testX, testY), callbacks=[lr_reduction, early_stopping], verbose=1)\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)\n",
        "\n",
        "# Get predictions and evaluate metrics\n",
        "predY = model.predict(testX)\n",
        "predY_classes = np.argmax(predY, axis=1)\n",
        "trueY_classes = np.argmax(testY, axis=1)\n",
        "\n",
        "unique_true_labels = np.unique(trueY_classes)\n",
        "class_report = classification_report(\n",
        "    trueY_classes, predY_classes,\n",
        "    target_names=[categories[i] for i in unique_true_labels],\n",
        "    output_dict=True,\n",
        "    zero_division=0\n",
        ")\n",
        "print(class_report)\n",
        "\n",
        "conf_matrix = confusion_matrix(trueY_classes, predY_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "accuracy_scores = accuracy_score(trueY_classes, predY_classes)\n",
        "f1_scores = f1_score(trueY_classes, predY_classes, average=None)\n",
        "print(\"Accuracy Scores: \", accuracy_scores)\n",
        "print(\"F1 Scores: \", f1_scores)\n",
        "print(\"Average F1 Score: \", np.mean(f1_scores))\n",
        "\n",
        "print(f\"Total Training Time: {end_time - start_time} seconds\")\n",
        "\n",
        "# Plot training & validation loss and accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Visualize test images\n",
        "plt.figure(figsize=(20, 15))\n",
        "displayed_count = {category: 0 for category in categories}\n",
        "max_images_per_class = 3\n",
        "displayed_images = 0\n",
        "\n",
        "for i in range(len(testX)):\n",
        "    if testX[i].size == 0:\n",
        "        continue  # Skip empty images\n",
        "\n",
        "    true_label = categories[trueY_classes[i]]\n",
        "    if displayed_count[true_label] < max_images_per_class:\n",
        "        plt.subplot(5, 6, displayed_images + 1)\n",
        "        plt.imshow(cv2.resize(testX[i][0], (128, 128)))\n",
        "        plt.title(f\"True: {true_label}\\nPred: {categories[predY_classes[i]]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        displayed_count[true_label] += 1\n",
        "        displayed_images += 1\n",
        "\n",
        "    if displayed_images >= max_images_per_class * len(categories):\n",
        "        break\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EEpVqTVrzxd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.applications import MobileNet\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Attention layer class\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "# Function to load and split dataset based on the category (Weaving or Knitting)\n",
        "def load_dataset_by_category(category_group):\n",
        "    base_dir = '/content/Fabric FDD/Fabric_classification/Fabric classification'\n",
        "\n",
        "    # Subcategories for the selected category group (either Weaving or Knitting)\n",
        "    subcategories = {\n",
        "        'Weaving_gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Weaving_dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Weaving_printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']\n",
        "    }\n",
        "\n",
        "    # Filter subcategories based on whether it's \"Weaving\" or \"Knitting\"\n",
        "    selected_subcategories = {k: v for k, v in subcategories.items() if category_group in k}\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    categories = list(selected_subcategories.keys())\n",
        "    category_counts = {category: 0 for category in categories}\n",
        "\n",
        "    for label, category in enumerate(categories):\n",
        "        for defect in selected_subcategories[category]:\n",
        "            category_dir = os.path.join(base_dir, category, defect)\n",
        "            if not os.path.exists(category_dir):\n",
        "                print(f\"Directory {category_dir} does not exist. Skipping this category.\")\n",
        "                continue\n",
        "            for filename in os.listdir(category_dir):\n",
        "                if filename.endswith('.jpg'):\n",
        "                    img = cv2.imread(os.path.join(category_dir, filename))\n",
        "                    img = cv2.resize(img, (128, 128))  # Resize image to 128x128\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                    category_counts[category] += 1\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    print(f\"Image counts per category for {category_group}:\", category_counts)\n",
        "\n",
        "    return images, labels, categories\n",
        "\n",
        "# Preprocess and train the model for either Weaving or Knitting\n",
        "def train_and_evaluate(category_group):\n",
        "    # Load the dataset for the specific category group\n",
        "    images, labels, categories = load_dataset_by_category(category_group)\n",
        "\n",
        "    # Ensure that we have images loaded\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(\"No images found. Please check the dataset path and ensure images are available.\")\n",
        "\n",
        "    # Preprocess the images (normalize pixel values)\n",
        "    images = images.astype('float32') / 255.0\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    labels = to_categorical(labels, num_classes=len(categories))\n",
        "\n",
        "    # Reshape images for LSTM input\n",
        "    images = images.reshape(images.shape[0], 1, 128, 128, 3)  # Reshaped for LSTM with 1 timestep\n",
        "\n",
        "    # Split the dataset into training and test sets\n",
        "    trainX, testX, trainY, testY = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Load pre-trained MobileNet without the top layers\n",
        "    feature_extractor = MobileNet(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "    # Freeze the weights of the pre-trained model\n",
        "    for layer in feature_extractor.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Define the model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Use TimeDistributed to apply the MobileNet to each image in the sequence\n",
        "    model.add(TimeDistributed(feature_extractor, input_shape=(1, 128, 128, 3)))\n",
        "    model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "\n",
        "    # Add LSTM layer to process the temporal aspect of the data\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Add the Attention layer\n",
        "    model.add(AttentionLayer())\n",
        "\n",
        "    # Add Dense layers for classification\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output layer for classification\n",
        "    model.add(Dense(len(categories), activation='softmax', kernel_regularizer='l2'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks for learning rate reduction and early stopping\n",
        "    lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    history = model.fit(trainX, trainY, epochs=90, batch_size=32, validation_data=(testX, testY), callbacks=[lr_reduction, early_stopping], verbose=1)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(testX, testY, verbose=0)\n",
        "    print(f'Test Loss for {category_group}:', loss)\n",
        "    print(f'Test Accuracy for {category_group}:', accuracy)\n",
        "\n",
        "    # Get predictions for the test set\n",
        "    predY = model.predict(testX)\n",
        "    predY_classes = np.argmax(predY, axis=1)\n",
        "    trueY_classes = np.argmax(testY, axis=1)\n",
        "\n",
        "    unique_true_labels = np.unique(trueY_classes)\n",
        "\n",
        "    # Print classification report\n",
        "    class_report = classification_report(\n",
        "        trueY_classes, predY_classes,\n",
        "        target_names=[categories[i] for i in unique_true_labels],\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(f\"Classification report for {category_group}:\\n\", class_report)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(trueY_classes, predY_classes)\n",
        "    print(f\"Confusion matrix for {category_group}:\\n\", conf_matrix)\n",
        "\n",
        "    accuracy_scores = accuracy_score(trueY_classes, predY_classes)\n",
        "    f1_scores = f1_score(trueY_classes, predY_classes, average=None)\n",
        "    print(f\"Accuracy Scores for {category_group}: \", accuracy_scores)\n",
        "    print(f\"F1 Scores for {category_group}: \", f1_scores)\n",
        "    print(f\"Average F1 Score for {category_group}: \", np.mean(f1_scores))\n",
        "\n",
        "    print(f\"Total Training Time for {category_group}: {end_time - start_time} seconds\")\n",
        "\n",
        "    # Plot training & validation loss and accuracy\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{category_group} Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{category_group} Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Train and evaluate models for Weaving and Knitting separately\n",
        "print(\"Training model for Weaving...\")\n",
        "train_and_evaluate('Weaving')\n",
        "\n",
        "print(\"\\nTraining model for Knitting...\")\n",
        "train_and_evaluate('Knitting')\n"
      ],
      "metadata": {
        "id": "rq_wCpMk7qUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Attention layer class (needed for loading the model)\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "# Function to load and split dataset based on the category (Weaving or Knitting)\n",
        "def load_test_dataset_by_category(category_group):\n",
        "    base_dir = '/content/Fabric FDD/Fabric_classification/Fabric classification'\n",
        "\n",
        "    subcategories = {\n",
        "        'Weaving_gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Weaving_dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Weaving_printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "        'Knitting_printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']\n",
        "    }\n",
        "\n",
        "    selected_subcategories = {k: v for k, v in subcategories.items() if category_group in k}\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    categories = list(selected_subcategories.keys())\n",
        "    category_counts = {category: 0 for category in categories}\n",
        "\n",
        "    for label, category in enumerate(categories):\n",
        "        for defect in selected_subcategories[category]:\n",
        "            category_dir = os.path.join(base_dir, category, defect)\n",
        "            if not os.path.exists(category_dir):\n",
        "                print(f\"Directory {category_dir} does not exist. Skipping this category.\")\n",
        "                continue\n",
        "            for filename in os.listdir(category_dir):\n",
        "                if filename.endswith('.jpg'):\n",
        "                    img = cv2.imread(os.path.join(category_dir, filename))\n",
        "                    img = cv2.resize(img, (128, 128))  # Resize image to 128x128\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                    category_counts[category] += 1\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    print(f\"Image counts per category for {category_group}:\", category_counts)\n",
        "\n",
        "    return images, labels, categories\n",
        "\n",
        "# Preprocess and evaluate the model for Weaving or Knitting\n",
        "def test_saved_model(category_group, saved_model_path):\n",
        "    # Load the dataset for the specific category group\n",
        "    images, labels, categories = load_test_dataset_by_category(category_group)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(\"No images found. Please check the dataset path and ensure images are available.\")\n",
        "\n",
        "    # Preprocess the images (normalize pixel values)\n",
        "    images = images.astype('float32') / 255.0\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    labels = to_categorical(labels, num_classes=len(categories))\n",
        "\n",
        "    # Reshape images for LSTM input\n",
        "    images = images.reshape(images.shape[0], 1, 128, 128, 3)  # Reshaped for LSTM with 1 timestep\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    model = load_model(saved_model_path, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "    # Evaluate the model on the test dataset\n",
        "    loss, accuracy = model.evaluate(images, labels, verbose=0)\n",
        "    print(f'Test Loss for {category_group}:', loss)\n",
        "    print(f'Test Accuracy for {category_group}:', accuracy)\n",
        "\n",
        "    # Get predictions for the test set\n",
        "    predY = model.predict(images)\n",
        "    predY_classes = np.argmax(predY, axis=1)\n",
        "    trueY_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "    # Print classification report\n",
        "    unique_true_labels = np.unique(trueY_classes)\n",
        "    class_report = classification_report(\n",
        "        trueY_classes, predY_classes,\n",
        "        target_names=[categories[i] for i in unique_true_labels],\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(f\"Classification report for {category_group}:\\n\", class_report)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(trueY_classes, predY_classes)\n",
        "    print(f\"Confusion matrix for {category_group}:\\n\", conf_matrix)\n",
        "\n",
        "    # Calculate accuracy and F1 scores\n",
        "    accuracy_scores = accuracy_score(trueY_classes, predY_classes)\n",
        "    f1_scores = f1_score(trueY_classes, predY_classes, average=None)\n",
        "    print(f\"Accuracy Scores for {category_group}: \", accuracy_scores)\n",
        "    print(f\"F1 Scores for {category_group}: \", f1_scores)\n",
        "    print(f\"Average F1 Score for {category_group}: \", np.mean(f1_scores))\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.matshow(conf_matrix, cmap='Blues', fignum=1)\n",
        "    plt.title(f'Confusion Matrix - {category_group}')\n",
        "    plt.colorbar()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.xticks(np.arange(len(categories)), categories, rotation=90)\n",
        "    plt.yticks(np.arange(len(categories)), categories)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "print(\"Testing saved model for Weaving...\")\n",
        "test_saved_model('Weaving', 'path_to_saved_weaving_model.h5')\n",
        "\n",
        "print(\"\\nTesting saved model for Knitting...\")\n",
        "test_saved_model('Knitting', 'path_to_saved_knitting_model.h5')\n"
      ],
      "metadata": {
        "id": "qw6ur_JB8fmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Attention layer class (needed for loading the model)\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "\n",
        "# Function to load and filter dataset based on user selection\n",
        "def load_test_dataset_by_user_selection(category_group, fabric_class):\n",
        "    base_dir = '/content/Fabric FDD/Fabric_classification/Fabric classification'\n",
        "\n",
        "    subcategories = {\n",
        "        'Weaving': {'gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                    'dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                    'printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']},\n",
        "        'Knitting': {'gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                     'dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                     'printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']}\n",
        "    }\n",
        "\n",
        "    if category_group not in subcategories or fabric_class not in subcategories[category_group]:\n",
        "        raise ValueError(\"Invalid category or sub-category selection.\")\n",
        "\n",
        "    selected_subcategory = subcategories[category_group][fabric_class]\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    categories = list(selected_subcategory)\n",
        "    category_counts = {category: 0 for category in categories}\n",
        "\n",
        "    for label, defect in enumerate(categories):\n",
        "        category_dir = os.path.join(base_dir, category_group, fabric_class, defect)\n",
        "        if not os.path.exists(category_dir):\n",
        "            print(f\"Directory {category_dir} does not exist. Skipping this category.\")\n",
        "            continue\n",
        "        for filename in os.listdir(category_dir):\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(category_dir, filename))\n",
        "                img = cv2.resize(img, (128, 128))  # Resize image to 128x128\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "                category_counts[defect] += 1\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    print(f\"Image counts per defect category for {category_group} - {fabric_class}:\", category_counts)\n",
        "\n",
        "    return images, labels, categories\n",
        "\n",
        "\n",
        "# Preprocess and evaluate the model based on user input\n",
        "def test_saved_model_by_user_input(saved_model_path):\n",
        "    # Ask user to select fabric type (Weaving or Knitting)\n",
        "    print(\"What type of fabric do you want to inspect?\")\n",
        "    fabric_type = input(\"Select: 1) Weaving 2) Knitting: \")\n",
        "\n",
        "    if fabric_type == '1':\n",
        "        category_group = 'Weaving'\n",
        "    elif fabric_type == '2':\n",
        "        category_group = 'Knitting'\n",
        "    else:\n",
        "        print(\"Invalid selection. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Ask user to select fabric class (Gray, Dyed, Printed)\n",
        "    print(f\"What is your fabric class for {category_group}?\")\n",
        "    fabric_class = input(\"Select: a) gray b) dyed c) printed: \")\n",
        "\n",
        "    if fabric_class == 'a':\n",
        "        fabric_class = 'gray'\n",
        "    elif fabric_class == 'b':\n",
        "        fabric_class = 'dyed'\n",
        "    elif fabric_class == 'c':\n",
        "        fabric_class = 'printed'\n",
        "    else:\n",
        "        print(\"Invalid selection. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Load the dataset based on the user's selection\n",
        "    images, labels, categories = load_test_dataset_by_user_selection(category_group, fabric_class)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(\"No images found. Please check the dataset path and ensure images are available.\")\n",
        "\n",
        "    # Preprocess the images (normalize pixel values)\n",
        "    images = images.astype('float32') / 255.0\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    labels = to_categorical(labels, num_classes=len(categories))\n",
        "\n",
        "    # Reshape images for LSTM input\n",
        "    images = images.reshape(images.shape[0], 1, 128, 128, 3)\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    model = load_model(saved_model_path, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "    # Evaluate the model on the test dataset\n",
        "    loss, accuracy = model.evaluate(images, labels, verbose=0)\n",
        "    print(f'Test Loss for {category_group} - {fabric_class}:', loss)\n",
        "    print(f'Test Accuracy for {category_group} - {fabric_class}:', accuracy)\n",
        "\n",
        "    # Get predictions for the test set\n",
        "    predY = model.predict(images)\n",
        "    predY_classes = np.argmax(predY, axis=1)\n",
        "    trueY_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "    # Print classification report\n",
        "    unique_true_labels = np.unique(trueY_classes)\n",
        "    class_report = classification_report(\n",
        "        trueY_classes, predY_classes,\n",
        "        target_names=[categories[i] for i in unique_true_labels],\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(f\"Classification report for {category_group} - {fabric_class}:\\n\", class_report)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(trueY_classes, predY_classes)\n",
        "    print(f\"Confusion matrix for {category_group} - {fabric_class}:\\n\", conf_matrix)\n",
        "\n",
        "    # Calculate accuracy and F1 scores\n",
        "    accuracy_scores = accuracy_score(trueY_classes, predY_classes)\n",
        "    f1_scores = f1_score(trueY_classes, predY_classes, average=None)\n",
        "    print(f\"Accuracy Scores for {category_group} - {fabric_class}: \", accuracy_scores)\n",
        "    print(f\"F1 Scores for {category_group} - {fabric_class}: \", f1_scores)\n",
        "    print(f\"Average F1 Score for {category_group} - {fabric_class}: \", np.mean(f1_scores))\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.matshow(conf_matrix, cmap='Blues', fignum=1)\n",
        "    plt.title(f'Confusion Matrix - {category_group} {fabric_class}')\n",
        "    plt.colorbar()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.xticks(np.arange(len(categories)), categories, rotation=90)\n",
        "    plt.yticks(np.arange(len(categories)), categories)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "test_saved_model_by_user_input('path_to_saved_model.h5')\n"
      ],
      "metadata": {
        "id": "uMDtohns-fs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Attention layer class (needed for loading the model)\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "\n",
        "# Function to load and filter dataset based on user selection\n",
        "def load_test_dataset_by_user_selection(category_group, fabric_class):\n",
        "    base_dir = '/content/Fabric FDD/Fabric_classification/Fabric classification'\n",
        "\n",
        "    subcategories = {\n",
        "        'Weaving': {'gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                    'dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                    'printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']},\n",
        "        'Knitting': {'gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                     'dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                     'printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']}\n",
        "    }\n",
        "\n",
        "    if category_group not in subcategories or fabric_class not in subcategories[category_group]:\n",
        "        raise ValueError(\"Invalid category or sub-category selection.\")\n",
        "\n",
        "    selected_subcategory = subcategories[category_group][fabric_class]\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    categories = list(selected_subcategory)\n",
        "    category_counts = {category: 0 for category in categories}\n",
        "\n",
        "    for label, defect in enumerate(categories):\n",
        "        category_dir = os.path.join(base_dir, category_group, fabric_class, defect)\n",
        "        if not os.path.exists(category_dir):\n",
        "            print(f\"Directory {category_dir} does not exist. Skipping this category.\")\n",
        "            continue\n",
        "        for filename in os.listdir(category_dir):\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(category_dir, filename))\n",
        "                img = cv2.resize(img, (128, 128))  # Resize image to 128x128\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "                category_counts[defect] += 1\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    print(f\"Image counts per defect category for {category_group} - {fabric_class}:\", category_counts)\n",
        "\n",
        "    return images, labels, categories\n",
        "\n",
        "\n",
        "# Preprocess and evaluate the model based on user input\n",
        "def test_saved_model_by_user_input(saved_model_path):\n",
        "    # Ask user to select fabric type (Weaving or Knitting)\n",
        "    print(\"What type of fabric do you want to inspect?\")\n",
        "    fabric_type = input(\"Select: 1) Weaving 2) Knitting: \")\n",
        "\n",
        "    if fabric_type == '1':\n",
        "        category_group = 'Weaving'\n",
        "    elif fabric_type == '2':\n",
        "        category_group = 'Knitting'\n",
        "    else:\n",
        "        print(\"Invalid selection. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Ask user to select fabric class (Gray, Dyed, Printed)\n",
        "    print(f\"What is your fabric class for {category_group}?\")\n",
        "    fabric_class = input(\"Select: a) gray b) dyed c) printed: \")\n",
        "\n",
        "    if fabric_class == 'a':\n",
        "        fabric_class = 'gray'\n",
        "    elif fabric_class == 'b':\n",
        "        fabric_class = 'dyed'\n",
        "    elif fabric_class == 'c':\n",
        "        fabric_class = 'printed'\n",
        "    else:\n",
        "        print(\"Invalid selection. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Load the dataset based on the user's selection\n",
        "    images, labels, categories = load_test_dataset_by_user_selection(category_group, fabric_class)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(\"No images found. Please check the dataset path and ensure images are available.\")\n",
        "\n",
        "    # Preprocess the images (normalize pixel values)\n",
        "    images = images.astype('float32') / 255.0\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    labels = to_categorical(labels, num_classes=len(categories))\n",
        "\n",
        "    # Reshape images for LSTM input\n",
        "    images = images.reshape(images.shape[0], 1, 128, 128, 3)\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    model = load_model(saved_model_path, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "    # Evaluate the model on the test dataset\n",
        "    loss, accuracy = model.evaluate(images, labels, verbose=0)\n",
        "    print(f'Test Loss for {category_group} - {fabric_class}:', loss)\n",
        "    print(f'Test Accuracy for {category_group} - {fabric_class}:', accuracy)\n",
        "\n",
        "    # Get predictions for the test set\n",
        "    predY = model.predict(images)\n",
        "    predY_classes = np.argmax(predY, axis=1)\n",
        "    trueY_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "    # Print classification report\n",
        "    unique_true_labels = np.unique(trueY_classes)\n",
        "    class_report = classification_report(\n",
        "        trueY_classes, predY_classes,\n",
        "        target_names=[categories[i] for i in unique_true_labels],\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(f\"Classification report for {category_group} - {fabric_class}:\\n\", class_report)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(trueY_classes, predY_classes)\n",
        "    print(f\"Confusion matrix for {category_group} - {fabric_class}:\\n\", conf_matrix)\n",
        "\n",
        "    # Calculate accuracy and F1 scores\n",
        "    accuracy_scores = accuracy_score(trueY_classes, predY_classes)\n",
        "    f1_scores = f1_score(trueY_classes, predY_classes, average=None)\n",
        "    print(f\"Accuracy Scores for {category_group} - {fabric_class}: \", accuracy_scores)\n",
        "    print(f\"F1 Scores for {category_group} - {fabric_class}: \", f1_scores)\n",
        "    print(f\"Average F1 Score for {category_group} - {fabric_class}: \", np.mean(f1_scores))\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.matshow(conf_matrix, cmap='Blues', fignum=1)\n",
        "    plt.title(f'Confusion Matrix - {category_group} {fabric_class}')\n",
        "    plt.colorbar()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.xticks(np.arange(len(categories)), categories, rotation=90)\n",
        "    plt.yticks(np.arange(len(categories)), categories)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "test_saved_model_by_user_input('path_to_saved_model.h5')\n"
      ],
      "metadata": {
        "id": "6dtkZuBvJuD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run fabric_inspection_app.py\n"
      ],
      "metadata": {
        "id": "KMcauUYn0LCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMUGSkTw0MHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Custom attention layer (needed for loading the model)\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "\n",
        "\n",
        "# Function to load and filter dataset based on user selection\n",
        "def load_test_dataset_by_user_selection(category_group, fabric_class):\n",
        "    base_dir = '/content/Fabric FDD/Fabric_classification/Fabric classification'\n",
        "\n",
        "    subcategories = {\n",
        "        'Weaving': {'gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                    'dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                    'printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']},\n",
        "        'Knitting': {'gray': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                     'dyed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective'],\n",
        "                     'printed': ['stain', 'damage', 'broken thread', 'holes', 'Non defective']}\n",
        "    }\n",
        "\n",
        "    if category_group not in subcategories or fabric_class not in subcategories[category_group]:\n",
        "        raise ValueError(\"Invalid category or sub-category selection.\")\n",
        "\n",
        "    selected_subcategory = subcategories[category_group][fabric_class]\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    categories = list(selected_subcategory)\n",
        "    category_counts = {category: 0 for category in categories}\n",
        "\n",
        "    for label, defect in enumerate(categories):\n",
        "        category_dir = os.path.join(base_dir, category_group, fabric_class, defect)\n",
        "        if not os.path.exists(category_dir):\n",
        "            st.write(f\"Directory {category_dir} does not exist. Skipping this category.\")\n",
        "            continue\n",
        "        for filename in os.listdir(category_dir):\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(category_dir, filename))\n",
        "                img = cv2.resize(img, (128, 128))  # Resize image to 128x128\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "                category_counts[defect] += 1\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    st.write(f\"Image counts per defect category for {category_group} - {fabric_class}: {category_counts}\")\n",
        "\n",
        "    return images, labels, categories\n",
        "\n",
        "\n",
        "# Preprocess and evaluate the model based on user input\n",
        "def test_saved_model_by_user_input(saved_model_path, category_group, fabric_class):\n",
        "    # Load the dataset based on the user's selection\n",
        "    images, labels, categories = load_test_dataset_by_user_selection(category_group, fabric_class)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        st.error(\"No images found. Please check the dataset path and ensure images are available.\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the images (normalize pixel values)\n",
        "    images = images.astype('float32') / 255.0\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    labels = to_categorical(labels, num_classes=len(categories))\n",
        "\n",
        "    # Reshape images for LSTM input\n",
        "    images = images.reshape(images.shape[0], 1, 128, 128, 3)\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    model = load_model(saved_model_path, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "    # Evaluate the model on the test dataset\n",
        "    loss, accuracy = model.evaluate(images, labels, verbose=0)\n",
        "    st.write(f'Test Loss for {category_group} - {fabric_class}: {loss}')\n",
        "    st.write(f'Test Accuracy for {category_group} - {fabric_class}: {accuracy}')\n",
        "\n",
        "    # Get predictions for the test set\n",
        "    predY = model.predict(images)\n",
        "    predY_classes = np.argmax(predY, axis=1)\n",
        "    trueY_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "    # Print classification report\n",
        "    unique_true_labels = np.unique(trueY_classes)\n",
        "    class_report = classification_report(\n",
        "        trueY_classes, predY_classes,\n",
        "        target_names=[categories[i] for i in unique_true_labels],\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "    st.write(f\"Classification report for {category_group} - {fabric_class}:\")\n",
        "    st.write(class_report)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(trueY_classes, predY_classes)\n",
        "    st.write(f\"Confusion matrix for {category_group} - {fabric_class}:\")\n",
        "    st.write(conf_matrix)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.matshow(conf_matrix, cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {category_group} {fabric_class}')\n",
        "    plt.colorbar()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.xticks(np.arange(len(categories)), categories, rotation=\n"
      ],
      "metadata": {
        "id": "gIulRKJj0OiF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}